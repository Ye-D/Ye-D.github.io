---
title: 'FALCON: Honest-Majority Maliciously Secure Framework for Private Deep Learning'
date: 2021-10-31
permalink: /posts/2021/10/blog-post-1/
tags:
  - MPC
  - Secret Sharing
  - Machine Learning
---
本次介绍的是S. Wagh等人发表在PoPETs'20上[FALCON](https://eprint.iacr.org/2021/459.pdf)


# Background

完全基于MPC的ML预测和训练一直是关注的热点，之前的SecureML、ABY3等论文一直在尝试这个难题。FALCON使用和ABY3同样的三方计算下的Replicated Secret Sharing方案来提升系统的计算和传输性能。和之前的方案不同的是，FALCON中完全使用算术秘密分享，但是使用了两个不同的环来处理线性计算（大环，$\mathbb{Z}_ L, L=32$ ）和非线性计算（小环，$\mathbb{Z}_{37}$）。首先，作者总结了现存方案，并和FALCON做了比较。

![image-20211030193435339](/images/FALCON/image-20211030193435339.png)

进一步，作者分别提出了针对各层的3PC下的计算协议。

# 基本原语

**Multiplication**：加法和数乘方法比较简单。针对线性层的乘法，包括矩阵乘法和卷积，则使用和ABY3相同的乘法和截断方法。乘法本身需要一次交互，截断则需要预处理生成的关联随机数。

**Reconstruction**：秘密恢复则需要每一方向下一方发送对方缺失的秘密分享。

**Select Shares** $\Pi_{\rm SS}$: 给定($[x]^L$​,$[y]^L$​, $[b]^2$​)，如果$b=0$​则返回$[x]^L$​，否则返回$[y]^L$​。本文首先生成关联随机数$[c]^2$​和$[c]^L$​。然后公开$b\oplus c=e$​。如果$e=1$​，令$[d]^L = [1-c]^L$​；否则，令$[d]^L=[c]^L$​。最后，计算$[z]^L = [(y-x)\cdot d]^L + [x]^L$​。​

**XOR with a public bit**: 对于一比特在环内的秘密分享$[x]^m$​和一个公开的比特值$b$​，要求$[y]^m=[x\oplus b]^m$​，可以计算$y=x+b - 2bx$​。因为$b$​是公开的，该计算不需要交互。

**Evaluating $[(-1)^\beta\cdot x]^m$​**：给定$[x]^m$和$[\beta]^m$，计算$[(1-2\beta)\cdot x]^m$即可。

# 核心模块

鉴于乘法等计算之前的博文已经介绍过很多次，这次仅介绍有关非线性计算的部分，即激活函数部分的计算。

## Private Compare

本文的比较方案和其他方案，例如ABY3等不同。在本文构建的Private Compare中，做比较之前，三方参与者已经得到了秘密分享值得比特分解，而且每一比特的分解是在$\mathbb{Z}_p$上的。本文的目标则是比较$x\ge r$，其中$r$是一个公开的数。鉴于$x$的比特分解已知，$r$是公开数，比较则可以和SecureNN中类似按比特比较。算法如下：

![image-20211030200927687](/images/FALCON/image-20211030200927687.png)

其中，$\beta$起到茫化作用，step-1-5计算式不需要交互的，step 6需要$\log_2\ell + 1$​​次交互。当$d=0$时，即说明$c[i]$中有一项为0。假设$c[t]=0$，$\beta=0$，那么$x[t]-r[t]=-1$；对于$i>t$，$w[i]=0$恒成立；如此$c[t]=0$。而对于 $i<t$，由于$w[t]=1$，$c[i]\ge 1$恒成立。所以在$x$和$r$最高不相同的比特位置，有$r[t]=1$ ，$x[t]=0$ 。那么$d=0$时 ，则有$x<r$ 。故而$\beta'=0$ 。否则当$d\neq 0$时有$\beta'=1$ 。

## Wrap Function

在$\mathbb{Z}_L$中，${\rm wrap}_2$定义如下
$$
{\rm wrap}_2 (a_1, a_2, L)=\begin{cases}
0, a_1 + a_2 <L\\
1, otherwise
\end{cases}
$$
对于三个数，有
$$
{\rm wrap}_{3e}(a_1, a_2, a_3, L)=\begin{cases}
0, \sum_{i=1}^3 a_i < L\\
1, L\le \sum_{i=1}^3 a_i < 2L\\
2, 2L \le sum_{i=1}^3 a_i < 3L

\end{cases}
$$
进一步，定义${\rm wrap}(a_1, a_2, a_3, L)={\rm wrap}_{3e}(a_1, a_2, a_3, L) \mod{2}$。

为了计算${\rm wrap}_3$，参与方首先生成随机数$[x]^L$，并生成$x$的每一比特在$\mathbb{Z}_p$中的算术分享$[x[i]]^p$，并生成$\alpha = {\rm wrap}_3(x_1, x_2, x_3,L)$d的比特分享$[\alpha]^2$。进一步，对于秘密值$a$，有：
$$
\begin{split}
r = a + x - \eta\cdot L\ (1)\\
r = r_1 + r_2 + r_3 - \delta_e\cdot L \ (2)\\
r_i = a_i + x_i - \beta_i \cdot L\ (3)\\
x = x_1 + x_2 + x_3 - \alpha_e \cdot L\ (4)\\
a = a_1 + a_2 + a_3 - \theta_e \cdot L \ (5)
\end{split}
$$
$(1)-(2)-(3)+(4)+(5)$有，
$$
\theta_e = \beta_1 + \beta_2 + \beta_3 + \delta_e - \eta-\alpha_e,
$$
上式 $\mod{2}$则得到$\theta = \beta_1 + \beta_2 + \beta_3 + \delta - \eta-\alpha$。需要注意的是(3)式包含三个式子。算法如下

![image-20211030203330261](/images/FALCON/image-20211030203330261.png)

在已知关联随机数的情况下，只需要Step4 交互计算（调用Private Compare）。

## ReLU

对于${\rm ReLU}(a)$，关键在于计算$a$最高有效位。本文的一个重要发现对于$a= a_1 + a_2 + a_3 \mod{L}$，有
$$
{\rm MSB}(a) =  {\rm MSB}(a_1) + {\rm MSB}(a_2) + {\rm MSB}(a_3) + c \mod{2}
$$
其中，$c$是三个$a_i$的低$\ell-1$位对于最高位的进位。即$c={\rm wrap}_3(2a_1, 2a_2, 2a_3, L)$。

如此，${\rm DReLU}(a)={\rm MSB}(a_1) \oplus {\rm MSB}(a_2) \oplus {\rm MSB}(a_3)\oplus {\rm wrap}_3(2a_1, 2a_2, 2a_3, L )\oplus 1$。得到${\rm DReLU}$之后，计算$\Pi_{\rm SS}$杰克得到激活函数结果。协议如下：

![image-20211030204203668](/images/FALCON/image-20211030204203668.png)

## Maxpool

池化层在协议层面和SecureNN一样，不同的是比较部分的计算调用本文构造的方案。

## Division \& BatchNorm

本文除法利用近似计算。本文首先计算除数的指数，即计算$2^\alpha \le x < 2^{\alpha +1}$中的$\alpha$。算法如下：

![image-20211030204601796](/images/FALCON/image-20211030204601796.png)

Step4中，$c=1$表示$x-2^{2^i+\alpha}\ge0$，则需要将当前指数加入最终结果。

得到$\alpha$​之后，进行如下计算

![image-20211030205047762](/images/FALCON/image-20211030205047762.png)

在该近似算法中，除数需要满足$b\in [0.5,1)$。本文采用的方法在于提取$\alpha$之后，将近似用的常数$2.9142$和$1$都扩大$2^{\alpha+1}$从而使得$b\in [0.5,1)$。最后结果截断乘法造成的scaling factor膨胀。

BatchNorm的算法如下：

![image-20211030205405796](/images/FALCON/image-20211030205405796.png)

除了计算均值和方差，剩下的部分和做除法类似，都是采用了近似算法。

# 实验效果

本文实验颇多，在此列举一下部分实验结果。

预测开销

![image-20211030205614905](/images/FALCON/image-20211030205614905.png)

![image-20211030205628770](/images/FALCON/image-20211030205628770.png)

训练开销

![image-20211030205641142](/images/FALCON/image-20211030205641142.png)

![image-20211030205652691](/images/FALCON/image-20211030205652691.png)

# 总结

本文在三方下基于算术电路提出了一种训练和预测的框架，在线计算的效率提升了很多。但是，关于预计算的关联随机数生成还是没有给出新的高效方案，只能用已有方案来做。