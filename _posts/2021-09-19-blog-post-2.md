---
title: 'FLASH: Fast and Robust Framework for Privacy-Preserving Machine Learning'
date: 2021-09-19
permalink: /posts/2021/09/blog-post-2/
tags:
  - MPC
  - Secret Sharing
  - Malicious with GOD
---
 本次介绍的论文是Byali, Megha等人发表在PoPETs'20上的 [FLASH](https://eprint.iacr.org/2019/1365).

# 1. 设计思想

之前介绍的有关PPML的论文，大多数还是围绕半诚实（semi-honest）模型展开的工作。核心的任务聚焦于在保证隐私的情况下尽可能的提升系统性能。除了ABY3保证了正确性（correct with abort）和ASTRA进一步保证了公平性（Fairness）。FLASH进一步实现了输出可达性（Guaranteed Output Delivery，GOD），即无论恶意敌手进行何种攻击诚实参与方都可以得到计算结果。FLASH采用了4方计算架构，在诚实大多数（最多1方是静态恶意敌手）情况下可以满足GOD安全。其核心的设计思想在于，当检测到恶意行为时可以定位到恶意方在两方之间（但是不能确定具体是哪一方），但是可以确定剩余的两方是诚实参与方。如此，则可以令诚实参与方获得数据明文，从安全计算转化为明文计算（不对诚实参与方保护隐私）。

# 2. 主要工作

1）FLASH首先基于Additive Shairing（$[\cdot]$-sharing）设计了4方下的Mirrored Sharing（$[\![\cdot]\!]$-sharing）方案；
2）进一步构造了Bi-Convey原语用来在4方下将$S_1$ 和 $S_2$共有的输入$x$在$T$的辅助下传送给$R$，该过程或者成功传送（$S_1$和$S_2$​没有恶意行为），或者$R$和$T$能确定敌手在（$S_1$，$S_2$）之间（之后$R$和$T$​交换各自的share恢复明文，进行明文计算）；
3）最终，关于乘法和比较等操作的构造，则是让每一次交互都可以抽象成一次Bi-Convey过程，从而使得整个系统能够满足GOD安全性要求；
4）进一步，FLASH构造了面向机器学习的计算模块，包括向量乘法、激活函数计算、截断、比特转化等，并对这些模块做了进一步优化。例如，向量乘法的通信量与向量大小无关、$\rm Sigmod$​​​​函数的近似等。并和ABY3、ASTRA进行了比较。性能的理论提升如下表。
![](/images/FLASHFig/theory_comp.png)

# 3. Mirrored Sharing Semantics

- Additive Sharing（$[\cdot]$​-sharing）：对于$x$，在2方下可以被分享为 $x^1$和$x^2$，满足$x=x^1 + x^2$​。其中每一个参与方持有一份。

- Mirrored Sharing（$[\![\cdot]\!]$​​-sharing）：对于$x$在4方下：

  - 存在$\sigma_x$和$\mu_x$满足：$\mu_x = x + \sigma_x$；

  - $\sigma_x$​被$[\cdot]$​-sharing分享在参与方$\rm E = \{E_1,E_2\}$​之间，即$[\sigma_x]_{\rm E_1}=\sigma_x^1$​，$[\sigma_x]_{\rm E_2}=\sigma_x^2$​。而参与方$\rm V=\{V_1, V_2\}$​则都持有$\sigma_x^1$​和$\sigma_x^2$​；

  - 类似的，$\mu_x$​ 被$[\cdot]$​-sharing 分享在$\rm V=\{V_1,V_2\}$​之间，即$[\mu_x]_{{\rm V}_1}=\mu_x^1$​，$[\mu_x]_{{\rm V}_2}=\mu_x^2$​。而$\rm E=\{E_1, E_2\}$​则都持有$\mu_x^1$​和$\mu_x^2$​。整体的语义分享如下：​​

    | $\rm E_1$：$[\![x]\!]_{\rm E_1}=(\sigma_x^1, \mu_x^1, \mu_x^2)$ | $\rm V_1$：$[\![x]\!]_{\rm V_1}=(\sigma_x^1, \sigma_x^2, \mu_x^1)$ |
    | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | $\rm E_2$​：$[\![x]\!]_{\rm E_2}=(\sigma_x^2, \mu_x^1, \mu_x^2)$​ | $\rm V_2$​：$[\![x]\!]_{\rm V_2}=(\sigma_x^1, \sigma_x^2, \mu_x^2)$​ |

    很显然，从$[\cdot]$-sharing 的线性性质可以很容易的推导出$[\![]\!]$-sharing 的线性，即支持非交互计算加法和明文-密文乘法。

# 4. Robust 4PC

## 4.1 Bi-Convey

如前所属，Bi-Convey $\Pi_{bic}(S_1,S_2,x,R,T)$在4方下将$S_1$ 和 $S_2$共有的输入$x$在$T$的辅助下传送给$R$，该过程或者成功传送（$S_1$和$S_2$没有恶意行为），或者$R$和$T$能确定敌手在（$S_1$，$S_2$）之间（之后$R$和$T$​​​​交换各自的share恢复明文，进行明文计算）。具体来说：

1. $S_1$和$S_2$​各自将$x$发送给$R$。同时，$S_1$和$S_2$将关于$x$的承诺$com(x)$发送给$T$。当然，关于承诺使用的随机数是相同的；
2. 如果$R$收到的$x$是相等的，那么$S_1$和$S_2$均没有作恶。$R$接受$x$，令$msg_R=continue$，并丢弃来自$T$的任何信息；否则，令$msg_R=I_R$，其中$I_R$表示$R$的share和随机数种子；
3. 对于$T$，如果收到的承诺相同，则令$msg_T=com(x)$；否则令$msg_T=I_R$​；
4. $R$和$T$互相交换msg；
5. 如果$msg_R=I_R$且$msg_T=com(x)$，则$R$接受和$msg_T$匹配的$x$。否则，$R$和$T$可以在本地恢复明文进行明文计算。

## 4.2 Input Sharing

在Input Sharing阶段，Dealer可能是恶意的敌手，那么其可能分发给不同的参与方的share不匹配。为了确认一致性，需要在share之后利用承诺进行验证。例如，如果Dealer是$\rm V_1$，在预计算阶段，所有的参与方根据共享的随机数种子生成（$\sigma_x^1, \sigma_x^2, \mu_x^1$）。在线计算阶段，$\rm V_1$计算$\mu_2 = x+ \sigma_x^1 + \sigma_x^2 -\mu_x^1$并把$\mu_x^2$发送给$\rm E$和$\rm V_2$。最后，$\rm E_1, E_2, V_2$利用承诺$com(\mu_x^2)$​来进行验证，取majority为最终分享结果。Dealer是其他参与方的情况类似。具体协议如下。
![](/images/FLASHFig/sh.jpg)

## 4.3 Circuit Evaluation

加法和明文-密文乘法比较容易，难点在于密文-密文乘法。对于乘法$z=xy$，$\rm E$中两方的目标是计算
$$
\begin{split}
\mu_z &= xy + \sigma_z\\
&= (\mu_x - \sigma_x)(\mu_y-\sigma_y)+ \sigma_z \\
&= \mu_x \mu_y -\mu_x \sigma_y - \mu_y \sigma_x + \sigma_x \sigma_y + \sigma_z
\end{split}
$$
令 $A= -\mu_x^1 \sigma_y - \mu_y^1 \sigma_x + \delta_{xy}+\sigma_z+\Delta$​，$B = -\mu_x^2\sigma_y -\mu_y^2\sigma_x - \Delta$​，其中$\delta_{xy}=\sigma_x \sigma_y$​。那么根据$[\![]\!]$​-sharing的语义，在预计算阶段的随机数生成基础上，$\rm V_1$​可以在本地计算$A$​，$\rm V_2$​可以在本地计算$B$​。但是这并不能保证$A$​和$B$​能够成功的被$\rm E$​获得。为了解决这个问题，进一步将$A$​和$B$​分解为$A=A_1+A_2$​，$B=B_1+B_2$​。其中，$A_j = -u_x^1 \sigma_y^j - \mu_y^1 \sigma_x^j + \delta_{xy}^j + \Delta_j$​被$\rm V_1$​和${\rm E}_j$​共有，$B_j = -u_x^2 \sigma_y^j - \mu_y^2 \sigma_x^j - \Delta_j$​被$\rm V_2$​和${\rm E}_j$​共有，$j\in \{1,2\}$​。如此一来，$A_j$​，$B_j$​则可以利用$\Pi_{bic}$​成功发送给$\rm E$​中两方。其中$\delta_{xy}^j， \Delta_j$​可以在预计算也利用共享随机数种子和原语$\Pi_{bic}$​生成。最终，$\rm E$在计算$\mu_z$之后便可以计算$\mu_z^2 = \mu_z - \mu_z^1$，并利用$\Pi_{bic}({\rm E}_1, {\rm E}_2, \mu_z^2, {\rm V}_2, {\rm V}_1)$将$\mu_z^2$发送给${\rm V}_2$​。具体协议$\Pi_{mult}$如下。
![](/images/FLASHFig/mult1.jpg)
![](/images/FLASHFig/mult2.jpg)

## 4.4 Output Computation

恢复算法比较直观，因为每一方缺失的份额都被其他三方持有，所以可以令其他三方中两方发送缺失的份额，而剩下的一方直接发送对应的哈希值，最终结果取majority。具体协议$\Pi_{oc}$如下。
![](/images/FLASHFig/oc.jpg)

# 5. ML Building Blocks

进一步构造面向ML计算的安全计算模块。

## 5.1  Arithmetic/Boolean Couple Sharing Primitive

在之后的计算中，会出现秘密值$x$只被$\rm{E}$或者${\rm V}$中两方持有，持有双方试图生成$[\![x]\!]$的情况。对于这种情况的sharing，可以令被另外两方完全持有的分享为0，从而减少开销。具体来说，如果$x$被$\rm E$中两方持有，则$\sigma_x^1 = \sigma_x^2=0$；如果$x$被$\rm V$中两方持有，则$\mu_x^1 = \mu_x^2=0$。具体协议$\Pi_{cSh}$​如下​。
![](/images/FLASHFig/csh.jpg)
注意，Case 2存在笔误：1)$\sigma_x^2 = -x - \sigma_x^1$； 2)$\Pi_{bic}({\rm V}_1, {\rm V}_2, \sigma_x^2, {\rm E}_2, {\rm E}_1)$。

## 5.2 Dot Product

对于向量内积 $z= \vec{\mathbf{x}}\bigodot \vec{\mathbf{y}}=\sum_{i=1}^d x_i y_i$​，可以简单的调用乘法协议$\Pi_{mult}$​完成，但是这会使得通信和向量大小正相关。为了使得通信量独立于向量大小​，可以借鉴ABY3中的方法，即现在share上做完加法求和再对求和结果进行通信。需要改变的则是对于$\delta^2_{xy}=\sum_{i=1}^d\delta_{x_i y_i}-\delta_{xy}^1$​的计算，类似的还有关于$A_j, B_j$​​的计算。其余计算则没有太大改变。具体协议$\Pi_{dp}$如下。
![](/images/FLASHFig/dp.jpg)

## 5.3 MSB Extraction

对于比较$u<v$，其等价于提取$a = u-v$的最高有效位 $msb(a)$。本文采取和ASTRA相同的设计思想：对于随机数$r\in \mathbb{Z}_{2^\ell}$，有$msb(a)= msb(r)\oplus msb(ra)$。因此，可以令参与方在预计算阶段生成$[\![r]\!]$和$[\![p]\!]^{\mathbf{B}}$，其中$p=msb(r)$。在线计算阶段，则求调用$\Pi_{mult}([\![r]\!], [\![a]\!])$并公开计算结果$ra$从而求得$q=msb(ra)$，然后计算$[\![q]\!]^{\mathbf{B}}$，最后计算$[\![msb(a)]\!]^\mathbf{B}=[\![p]\!]^\mathbf{B}\oplus [\![q]\!]^\mathbf{B}$。但是利用乘法隐藏真实值是有一定的泄露的：例如，如果$r$是奇数，而公开的$ra$是偶数，那么$a$​一定是偶数。所以，这种方法的安全性并不如one-time-pad。​
![](/images/FLASHFig/msb.jpg)

## 5.4 Truncation

为了防止多次连续乘法造成溢出，本文截断方案采取类似ABY3中的截断方法：首先生成$(r, r^t)$​的秘密分享，其中$r^t = r/2^d$​​。在线计算计算，乘法计算完成时公开$z-r$​，并截断$z-r$​获得$(z-r)^t$​。进一步，利用协议$\Pi_{cSh}({\rm E}, (z-r)^t)$​生成$[\![(z-r)^t]\!]$​，并计算最后结果$[\![z^t]\!]=[\![(z-r)^t]\!]+[\![r^t]\!]$​。具体协议$\Pi_{mulTr}^A$​​如下。
![](/images/FLASHFig/mulTr.jpg)

## 5.5 Bit Conversioni_

在5.3节中，协议$\Pi_{msb}$求得的是Boolean shares。但是计算得到Boolean shares之后，ML中后续的任务往往又涉及到乘法等算术计算。因此，需要将Bit的Boolean shares转化为等价的Arithmetic shares。对于比特 $b$，有：
$$
b = \mu_b \oplus \sigma_b = \mu_b' + \sigma_b' - 2\mu_b' \sigma_b'
$$
其中，$\mu_b'$和$\sigma_b'$是对应比特值的算术表示，明文持有他们的参与者（$\rm E$中两方持有$\mu_b$， $\rm V$中两方持有$\sigma_b$​）可以在本地进行转化。因此，难点在于计算最后一个乘法。利用前文设计的$\Pi_{cSh}$协议和$\Pi_{mult}$，可以完成Bit Conversion。具体协议$\Pi_{btr}$如下。
![](/images/FLASHFig/btr.jpg)

## 5.6 Bit Insertion

给定Boolean shared的比特 $[\![b]\!]^\mathbf{B}$​和Arithmetic shared的$[\![x]\!]$，求$[\![bx]\!]$在ML计算中是很常见的一种操作，比如$\rm ReLU$。一种直接的方法可以首先调用$\Pi_{btr}([\![b]\!]^\mathbf{B})$实现Bit Conversion然后再调用协议$\Pi_{mult}$​实现乘法。进一步，本文提出了如下方法减少通信量和通信轮数。具体来说，对于
$$
\begin{split}
\mu_{bx}&=(\mu_b\oplus \sigma_b)\cdot (\mu_x - \sigma_x) + \sigma_{bx}\\
&= (\mu_b' + \sigma_b' - 2\mu_b' \sigma_b')\cdot  (\mu_x - \sigma_x) + \sigma_{bx}\\
&= \gamma_{b'x} - \mu_{b'}\sigma_x + (\mu_x - 2\gamma_{b'x})\sigma_{b'} + (2\mu_{b'}-1)\delta_{b'x} + \sigma_{bx}
&= \gamma_{b'x} + ( - \mu_{b'}^1\sigma_x + (\mu_x^1 - 2\gamma_{b'x}^1)\sigma_{b'} + (2\mu_{b'}^1-1)\delta_{b'x} + \sigma_{bx})\\
&+ (- \mu_{b'}^2\sigma_x + (\mu_x^2 - 2\gamma_{b'x}^2)\sigma_{b'} + (2\mu_{b'}^2-1)\delta_{b'x})\\
&= \gamma_{b'x} + (A_1 + A_2) + (B_1 + B_2)
\end{split}
$$
其中， $\gamma_{b'x}= \mu_{b'}\mu_x$​, $\delta_{b'x}=\sigma_{b'}\sigma_x$​。如此，参与方可以首先对于$\rm V$​生成关于$\mu_{b'}$​和$\gamma_{b'x}$​的$[\cdot]$​-shares，对于$\rm E$​生成关于$\sigma_{b'}$​和$\delta_{b'x}$​的$[\cdot]$​​-shares，如此参与方可以本地计算$A_1$, $A_2$, $B_1$, $B_2$​（每一项都被2个参与方共有）。最后，调用$\Pi_{bic}$实现传输并计算最终的$\mu_{bx}$。具体协议$\Pi_{bin}$​如下。
![](/images/FLASHFig/bin.jpg)

# 6. Evaluation

本文做了关于关键模块的性能测试，进一步进行了ML模型的性能实验。对于ML中的算子，矩阵乘法、卷积可以归约到向量乘法，$\rm Sigmoid$可以用分段函数计算（分段方法和SecureML一样），而$\rm ReLU$​则使用可以先做再求乘积。实验结果和ABY3进行比较。

## 6.1 模块实验

### 1）Dot Product：

首先在固定向量长度下比较FLASH和ABY3的Latency；
![](/images/FLASHFig/edp.jpg)

其次，比较性能在特征增加时带来的Latency变化。
![](/images/FLASHFig/edp2.jpg)

### 2）MSB Extraction

首先比较一次协议调用的Latency：
![](/images/FLASHFig/emsb.jpg)

进一步，比较多次调用的Latency增长趋势：
![](/images/FLASHFig/emsb2.jpg)

### 3）Truncation

Latency 和 Throughput 比较如下：
![](/images/FLASHFig/trunc.jpg)![](/images/FLASHFig/trunc2.jpg)

### 4）ML Evaluation

首先比较关于线性回归和Logistic回归的Latency。
![](/images/FLASHFig/ml1.jpg)

接下来，比较两种回归的Throghput。
![](/images/FLASHFig/ml2.jpg)![](/images/FLASHFig/ml3.jpg)

最后比较NN模型的Latency和Throghtput。
![](/images/FLASHFig/ml4.jpg)![](/images/FLASHFig/ml5.jpg)

# 7. 结论

本文是比较早的一项实现GOD安全性的安全ML的工作，而且不再需要用广播。对后来的工作有很多借鉴意义。但是，也有许多需要改进之处，例如如何在实现GOD的情况下实现Privacy尚未得到很好的解决。