---
title: 'CryptGPU: Fast Privacy-Preserving Machine Learning on the GPU'
date: 2022-01-26
permalink: /posts/2022/01/blog-post-1/
tags:
  - MPC
  - Secret Sharing
  - Machine Learning
  - GPU
---

这次分享的是Sijun Tan等人发表在IEEE S&P'21的[CryptGPU](https://arxiv.org/abs/2104.10949)。

## Background & Motivation
目前大多数基于安全多方计算（MPC）的隐私保护机器学习方案都是运行在CPU上的，但是在明文机器学习领域GPU已经成为一项不可缺少的硬件设备。GPU强大的算力能够大大加快机器学习模型，尤其是神经网络的计算速度。为了让MPC的隐私保护机器学习方案也能够充分利用GPU的计算性能、加快基于MPC的隐私保护机器学习训练和预测效率，本文提出了CryptGPU。

本文的主要贡献在于将基于MPC的密码学协议迁移到GPU上，实现了大幅度的性能优化。然而，将MPC技术从CPU迁移到GPU会遇到一系列的挑战。虽然NVIDIA的CUDA平台能够支持一般性的计算，但是将面向CPU的代码直接运行在GPU上并不能直接带来预期的性能提升。为了实现高效的基于GPU的MPC技术，设计者必须要处理CPU和GPU之间的架构差异：
1. 利用已有的CUDA Kkernels：第一个挑战则是现有的面向深度学习的、高度优化的CUDA kernels是面向浮点数（floating-point）计算设计的，并且这些kernels并不能直接在整数（integers）上计算。而MPC计算则主要计算在离散空间（环或者域）。为了利用现有的、高度优化的CUDA kernels，我们必须将整数计算无损地嵌入到浮点数计算中。为了解决这个问题，CryptGPU 构造了 'CUDALongTensor' 类，其能够对整数张量进行建模，并将整数计算无损的转化为对应的浮点数计算。
2. GPU友好的密码技术：GPU的架构适合对一块数据（block）进行简单快速的计算，例如component-wise的加法和乘法。但是，GPU却对条件语句不是很友好。因此，虽然现有的GPU可以支持整数加法，但是在取素数模下做整数加法、乘法会造成大量开销（例如，对于point-wise加法40倍的差距）。因此，将密码学技术迁移到GPU上必须要考虑这些架构影响。例如，和姚氏混乱电路相比，基于向量化秘密分享的MPC协议更能发挥GPU的并行性能。进一步，为了避免模素数运算，CryptGPU采用模 $\mathbb{Z}_{2^k}$ 的环，例如 $\mathbb{Z}_{2^{64}}$ 。

实验显示，对于Falcon中基于CPU的线性层方案，CryptGPU可以带来25-72倍的性能提升。对于卷积操作（卷积核和数据都是秘密分享的），CryptGPU快150倍。即便是对非线性函数，例如ReLU，CryptGPU也能带来10倍的加速。最后，作者在CrypTen的技术上实现了CryptGPU并开源，[链接](https://github.com/jeffreysijuntan/CryptGPU)。


## Systen Design and Architecture
如前所述，CrypGPU的设计原则：1）充分利用现有的线性代数计算CUDA kernerls；2）使所有的计算都在GPU上进行。CryptGPU面向64比特的整数环上的计算，而现有的GPU线性计算库却是支持64比特浮点数。接下来将主要如何将 $\mathbb{Z}_{2^{64}}$ 上的 整数计算无损的嵌入到54比特浮点数计算中。为了实现这个目标，本文有如下最重要的观察：
1. Exact Computation for Small Values: 64比特的浮点数具有52比特的精度，而且可以表示所有在区间 $[-2^{52}, 2^{52}]$ 内的整数。也就是说，我们可以准确计算乘法$ab$，其中 $a,b \in \mathbb{Z} \cap [-2^{26}, 2^{26}]$。
2. Bilinearity: 矩阵乘法和卷积操作被称为双线性操作（bilinear）。即对于任意 $\mathbf{A}_0, \mathbf{A}_1, \mathbf{B}_0, \mathbf{B}_1$，有
$
(\mathbf{A}_0 +\mathbf{A}_1) \circ (\mathbf{B}_0+\mathbf{B}_1)= \mathbf{A}_0 \circ \mathbf{B_0} + \mathbf{A}_0 \circ \mathbf{B}_1 + \mathbf{A}_1 \circ \mathbf{B}_0 + \mathbf{A}_1 \circ \mathbf{B}_1,
$
其中 $\circ$ 表示任意双线性计算。假设我们将输入表示为更小的基的形式，那么有$\mathbf{A} = \mathbf{A}_0+2^{16} \mathbf{A}_1$ 和 $\mathbf{B}=\mathbf{B}_0+2^{16}\mathbf{B}_1$ 。 双线性保证了 $\mathbf{A}\circ \mathbf{B}$ 可以通过 $\mathbf{A}_0 \circ \mathbf{B_0}, \mathbf{A}_0 \circ \mathbf{B}_1, \mathbf{A}_1 \circ \mathbf{B}_0, \mathbf{A}_1 \circ \mathbf{B}_1$ 的线性组合来获得。线性组合的过程只涉及到 element-wise 加法和数乘。
3. CUDA kernerls for element-wise operations: 现有的CUDA kernerls可以支持整数上的element-wise加法和数乘。

为了实现双线性操作 $\circ$, 例如矩阵乘法和卷积，CryptGPU首先将输入矩阵 $\mathbf{A}, \mathbf{B} \in \mathbb{Z}_{2^{64}}^{n\times m}$ 分解为数值范围小的若干个矩阵组合 $\mathbf{A}_1,...,\mathbf{A}_k$ 和 $\mathbf{B}_1,...,\mathbf{B}_k \in \mathbb{Z}_{2^w}^{n\times m}$，满足 $\mathbf{A}=\sum_{i=1}^k 2^{(i-1)w}\mathbf{A}_i$ 和 $\mathbf{B}=\sum_{i=1}^k 2^{(i-1)w}\mathbf{B}_i$。进一步，利用浮点数CUDA kernerls在GPU上求$k^2$个$\mathbf{A}_i \circ \mathbf{B}_j$。因为$\mathbf{A}_i \circ \mathbf{B}_j$ 的取值范围不会超过 $2^{52}$，这些中间结果都可以准确计算。最终，这些成对的乘积被重新解释编码为64比特的整数。如此，$\mathbf{A} \circ \mathbf{B}$ 可以通过 $\mathbf{A}_i\circ \mathbf{B}_j$ 的线性组合计算得到。因为最终的结果需要模 $2^{64}$，所以只需要计算下标满足 $w(i+j-2)<64$ 的 $\mathbf{A}_i\circ \mathbf{B}_j$。在计算浮点数卷积的时候，CryptGPU取 $k=4, w=16$。如此每个双线性计算被分解为10个成对的双线性积。另外，有如下三个Remark:
1. Smaller Number of Blocks： 直觉上可以设 $k=3$ 从而每个块需要包含22比特的值。乘法得到44比特的值不会超过范围，但是矩阵乘法或者卷积中的加法使得只能进行 $2^8=256$ 次加法，这在实际应用中很快就会被超过。如果分为 $k=4$ 块，每块包含 $16$ 比特的值，那么可以进行 $2^{20}$ 的中间加法，可以满足实际应用。
2. Overhead of Block-wise Decomposition: 每个双线性计算被分解为 $O(k^2)$ 个同样大小的双线性计算，为了减少计算开销，CryptGPU利用GPU的并行技术同时进行多个计算。对于卷积，利用 cudnnConvolutionForward 加速；对于矩阵乘法，利用 cublasSgemm 加速。对于小输入($64\times 64$)，只带来2倍的额外计算开销；对大的输入($224\times 224$)，额外引入$9\times$的时间。虽然时间开销引入的不多，但是带来了很大的存储需求，因此大大限制了在隐私训练中的batchsize。
3. Comparsion with Delphi: 之前的Delphi方案也提出利用GPU提升计算性能，但是该方案是面向数据是秘密分享，模型是对服务器一方来说是明文的情况（类似MiniONN）。所以，该方案可以限制参数和卷积、矩阵乘法结果不超过 $[-2^{52}, 2^{52}]$。实际参数上，Delphi选择了环 $\mathbb{Z}_{2^{32}}$ 和15比特的小数部分精度。而CryptGPU是完全计算在秘密分享上的，而且扩展到了更深的神经网络和更大的数据集上。

CUDALongTensor abstraction: CryptGPUt提供了CUDALongTensor来将64比特整数计算嵌入到64比特的浮点算术计算。基于CrypTen中的 MPCTensor，本文实现了 CUDALongTensor。在计算中：
1. 如果现有的CUDA kernerls能够支持该运算，例如element-wise加法和乘法，直接利用现有的CUDA kernerls;
2. 而在卷积和矩阵运算双线性计算，则调用 CUDALongTensor。

## Threat Model & Cryptographic Design
接下来介绍威胁模型和协议设计。
### Threat Model
CryptGPU适用于三方计算，能够在诚实大多数（honest-majority）场景下抵抗半诚实的敌手，保护数据隐私。在计算过程中，所有的数据都是在秘密分享模式下。本文忽略输入分享和输出重构的一点开销，着重于计算过程中的开销。

### Cryptographic Building Blocks for Private Inference
CryptGPU采用ABY3中的2-out-of-3 replicated secret sharing，数据和模型都以秘密分享的形式分布在三个不合谋的服务器上。为了编码浮点数，本文和之前的方案一样将浮点数保留 $t=20$ 比特小数位，并编码到 $\mathbb{Z}_{2^{64}}$。
1. Protocol Intialization: 协议初始化将生成用于resharing的随机数，具体见ABY3；
2. Linear Operations：包括加法和线性组合（权重是明文），该部分不需要交互；
3. Multiplication： 乘法需要本地计算得到3-out-of-3 sharing之后进行一次resharing，需要一次交互。额外的，要进行rescale，截断$t$比特小数位防止高位溢出。本文采用ABY3中的第一种截断方法。如此，一共需要两轮交互。
4. Convolution & Matrix Multiplication: 调用前文提到的分解方案方法分解输入，进行卷积或者矩阵乘法，然后线性组合得到结果。分解之后的计算和ABY3中的计算一样。
5. Most Significant Bit: 为了计算激活函数，要首先提取输入 $[x]^n=(x_1, x_2, x_3)$ 的最高有效位。本文采用ABY3中A2B的方法，对 $[x_1]^2=(x_1,0,0)$, $[x_2]^2=(0,x_2,0)$，和 $[x_3]^2=(0,0,x_3)$ 运行加法电路求和，得到 $[x]^2$。然后提取最高位 $[msb(x)]^2$。这需要 $\log_2(n)$ 轮交互。
6. ReLU: 得到 $msb(x)$ 之后，调用ABY3中的 bit injection协议可以计算ReLU。

### Cryptographic Building Blocks for Private Training
为了实现基于SGD的深度学习模型训练，我们需要计算softmax函数。对于输入 $[\mathbf{x}, \mathbf{y}]$, 其交叉熵损失为 $\ell_{\mathsf{CE}}(\mathbf{x}, \mathbf{y})= -\sum_{i\in [d]}y_i \log \widetilde{z}_i$, 其中 $\widetilde{\mathbf{z}}=\mathsf{softmax}(\mathbf{z})$. 对于 $\mathbf{x}\in \mathbb{R}^d$, $\mathsf{softmax}$ 定义为 
$$\mathsf{softmax}_i(\mathbf{x})=e^{x_i}/(\sum_{i\in [d]} e^{x_i}).$$ 
因此，输出层的梯度计算为 $\bigtriangledown_\mathbf{z}\ell_{\mathsf{CE}}=\mathsf{softmax}(\mathbf{z})-\mathbf{y}$。可以看到，我们不需要交叉熵的值，所以不需要计算 $\log(\cdot)$ 函数。

1. Softmax: 首先，为了限制输入的范围，在做 $\mathsf{softmax}$ 之前，先对其正则化 $(\mathbf{x}-\mathsf{max}_i x_i)$。由于 $\mathsf{softmax}(\mathbf{x}-\mathsf{max}_i x_i)=\mathsf{softmx}(\mathbf{x})$，这种变化并不会影响训练结果。正则化之后，$e^{x_i}$中 $x_i\le 0$ ,从而使得 $\mathsf{softmax}$ 计算中的分母在 $[1,d]$ 中。
2. Exponentiation：为了近似计算指数函数 $e^x$，本文采用极限表征
$
f_m (x)= (1+\frac{x}{m})^m.
$
根据 $\ln(1+x)$ 的泰勒展开，在 $|x|<m$ 的条件下，有
$
\frac{f_m(x)}{e^x} = \frac{e^{m\ln(1+x/m)}}{e^x} = e^{-O(x^2/m)}.
$
因此，degree-$m$ 的 $f_m$ 在以0为中心的 $O(\sqrt{m})$ 范围内近似 $e^x$。另一种方法是用泰勒级数近似，虽然该方法可以使用 degree-$m$ 的多项式在 $O(m)$范围内提供更好的近似，但是该方法:
    - 计算degree-$m$ 多项式需要 $m$ 次乘法和 $O(\log_2(m))$ 次交互，而计算 $f_m$ 只需要 $\log_2m$ 次乘法；
    - 泰勒级数需要的系数可以取到 $\frac{1}{m!}$，在定点表示下很可能近似为0。虽然我们可以使用 $\Pi_{i\in [m]}\frac{x}{i}$ 来计算 $x^m/m!$，但是这需要 $O(m)$ 轮乘法。
    - 在我们的设置中，$e^x$ 的输入范围是 $[-\infty, 0]$, 并且 $f_m$具有当 $x\rightarrow -\infty$, $f_m\rightarrow 0$ 的趋势，这和 $e^x$ 是一致的。而泰勒级数当 $x\rightarrow -\infty$时，则是发散的，会带来很大误差（除非degree特别高）。在本文中， $x\in [-45,0]$，这需要degree非常高的泰勒级数。

    所以，本文采用 $f_m$ 近似 $e^x$ 计算。具体实验中，取 $m=2^9=512$。因此计算$f_m$需要 $\log_2m=9$ 轮乘法。在 $t=20$的情况下，对于 $\forall x\le 0$，误差 $\le 6\cdot 10^{-4}$.

3. Division：给定 $[x]^n$ 和 $[y]^n$, 求 $[x/y]^n$。本文中的输入 $1\le y\in Y$。为了计算倒数 $[1/y]^n$，和之前的工作一样，本文采用基于Newton-Raphsion的迭代近似算法。给定初始解 $z_0$, 迭代计算 $z_i = 2z_{i-1}-yz_{i-1}^2$。令初始解 $z_0=1/Y$，$O(\log_2Y)$次迭代就能得到 $1/y$ 非常准确的近似值。具体来说，$error_i = |1/y-z_i|=\frac{1}{y}|1-z_iy|\le \varepsilon$，其中 $\varepsilon=|1-z_iy|$。代入迭代算法，有 $\varepsilon_i = \varepsilon_{i-1}^2$. $i$ 次迭代之后，误差 $(1-1/Y)^{2^i}\le e^{-2^i/Y}$。在实验中，$Y=200$, 迭代13次，$t=20$ 情况下，在 $[1,Y]$ 内的输入误差 $\approx 10^{-4}$ （浮点数计算误差 $\approx 10^{-9}$）。
4. Maximum：求最大值则是两个组做个减法然后求差的 $msb$，然后做个乘法即可。对于 $n$ 个数中求最大值，则是采用tree-manners从而只需要 $\log_2m$ 交互复杂度。
5. DReLU：求 $\mathrm{ReLU}(x)$ 的导数，只需要求得 $\mathrm{msb}(x)\oplus 1$即可。

## Evaluation
本文基于CryTen实现了CrypGPU本文进行了大量的实验，并在LeNet, AlexNet, 和ResNet上和之前的方案进行了对比。三方使用带宽1.25GB/s、延迟0.2ms的局域网连接。为了更好的性能，本文将Max-Pooling替换为Average-Pooling。

### Private Inference

![](/images/CryptGPU/1.jpg)

从表1可以看出，对于VGG16，CryptGPU比FALCON快$3.7\times$；但是对于小模型，FALCON性能更好。这是因为小模型不能充分显示GPU的并行能力。和CrypTFlow相比，CryptGPU快大约$2.2\times$。但是和GPU上的明文预测相比，还有$1000\times$的差距。

![](/images/CryptGPU/2.jpg)

进一步，表2和3显示了CryptGPU在batch inference下的性能提升。均摊时间有了$12-53\times$的提升。

### Private Training

![](/images/CryptGPU/3.jpg)

如表4，对于模型训练，CryptGPU比FALCON减少时间开销达$7-36\times$。但是和GPU明文训练相比，还有$2000\times$差距。

![](/images/CryptGPU/4.jpg)

如表5，和FALCON相比，CryptGPU提升线性层的性能达到$25-70\times$。不过对于$\mathrm{ReLU}$函数，FALCON中的方法和本文采用的A2B方法性能差距不大，而且对于小模型，FALCON中的方法更加高效。

### Microbenchmarks

![](/images/CryptGPU/5.jpg)

图1展示了对于不同的卷积和输入大小，GPU的方案大大优于CPU方案。大约有$10-174\times$的提升。

![](/images/CryptGPU/6.jpg)

如图2，对于ReLU函数，GPU也可以加速（同样的计算协议）。实验中大约有$9-16\times$的时间提升。

![](/images/CryptGPU/7.jpg)

图3是相对误差随着比特位数的变化，大约15比特的小数位就能达到$1\%$的误差。

![](/images/CryptGPU/8.jpg)

表6展示了在ResNet上的预测相对误差，不超过$0.021\%$。

![](/images/CryptGPU/9.jpg)

图4展示了训练交叉熵随着训练迭代的变化，CryptGPU和明文训练基本一致。

![](/images/CryptGPU/10.jpg)

表7是验证集准确率，差距小于$1\%$。

![](/images/CryptGPU/11.jpg)

最后，验证了将Max-Pooling替换为Average-Pooling带来的准确率影响。对AlexNet带来了$3\%$的降低，对VGG反而增加了$1\%$的准确率。这表明替换并不会对模型性能带来显著降低。

## Conclusion
本文使用的协议都是经典协议，但是却利用GPU实现了大幅度的性能提升。不过本文的实验都是在LAN下进行的，在WAN下通信带来的开销是否会显著降低这种提升很值得探索一下。最近还有其他的论文也在探索利用GPU等硬件加速安全协议，值得进一步的学习。

